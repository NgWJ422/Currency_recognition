{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74c3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b065485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Projects-Ng\\Currency_recognition\\assets\\image1.jpg: 320x640 1 RM100, 1596.1ms\n",
      "Speed: 376.8ms preprocess, 1596.1ms inference, 221.6ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 480x640 (no detections), 298.2ms\n",
      "Speed: 74.3ms preprocess, 298.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 188.1ms\n",
      "Speed: 3.2ms preprocess, 188.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM1, 220.4ms\n",
      "Speed: 31.9ms preprocess, 220.4ms inference, 41.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 275.5ms\n",
      "Speed: 2.8ms preprocess, 275.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 256.9ms\n",
      "Speed: 5.4ms preprocess, 256.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 264.8ms\n",
      "Speed: 3.2ms preprocess, 264.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 291.3ms\n",
      "Speed: 3.0ms preprocess, 291.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 265.7ms\n",
      "Speed: 2.8ms preprocess, 265.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 303.4ms\n",
      "Speed: 2.9ms preprocess, 303.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM50, 309.7ms\n",
      "Speed: 3.2ms preprocess, 309.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 289.3ms\n",
      "Speed: 2.9ms preprocess, 289.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 1 RM50, 331.0ms\n",
      "Speed: 3.7ms preprocess, 331.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM50, 348.9ms\n",
      "Speed: 2.4ms preprocess, 348.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM50, 301.4ms\n",
      "Speed: 3.7ms preprocess, 301.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM1, 1 RM50, 240.7ms\n",
      "Speed: 3.1ms preprocess, 240.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 250.7ms\n",
      "Speed: 2.9ms preprocess, 250.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 260.2ms\n",
      "Speed: 2.8ms preprocess, 260.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 242.2ms\n",
      "Speed: 2.6ms preprocess, 242.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 231.1ms\n",
      "Speed: 2.8ms preprocess, 231.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 267.9ms\n",
      "Speed: 2.7ms preprocess, 267.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 246.3ms\n",
      "Speed: 3.2ms preprocess, 246.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 238.0ms\n",
      "Speed: 3.2ms preprocess, 238.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 253.6ms\n",
      "Speed: 2.4ms preprocess, 253.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 265.6ms\n",
      "Speed: 3.2ms preprocess, 265.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 245.8ms\n",
      "Speed: 2.4ms preprocess, 245.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 248.0ms\n",
      "Speed: 2.5ms preprocess, 248.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 256.0ms\n",
      "Speed: 2.6ms preprocess, 256.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 264.1ms\n",
      "Speed: 2.5ms preprocess, 264.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 311.6ms\n",
      "Speed: 2.6ms preprocess, 311.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 255.1ms\n",
      "Speed: 2.8ms preprocess, 255.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 1 RM50, 265.4ms\n",
      "Speed: 2.7ms preprocess, 265.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 1 RM50, 280.3ms\n",
      "Speed: 3.3ms preprocess, 280.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 1 RM50, 277.4ms\n",
      "Speed: 3.9ms preprocess, 277.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 274.3ms\n",
      "Speed: 2.7ms preprocess, 274.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 265.2ms\n",
      "Speed: 3.2ms preprocess, 265.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 239.5ms\n",
      "Speed: 2.8ms preprocess, 239.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 233.9ms\n",
      "Speed: 2.7ms preprocess, 233.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 256.0ms\n",
      "Speed: 2.3ms preprocess, 256.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 253.7ms\n",
      "Speed: 3.0ms preprocess, 253.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 253.2ms\n",
      "Speed: 2.4ms preprocess, 253.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 267.5ms\n",
      "Speed: 2.9ms preprocess, 267.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 305.6ms\n",
      "Speed: 3.2ms preprocess, 305.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 1 RM50, 271.1ms\n",
      "Speed: 2.8ms preprocess, 271.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 247.5ms\n",
      "Speed: 2.7ms preprocess, 247.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 311.3ms\n",
      "Speed: 3.5ms preprocess, 311.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 387.0ms\n",
      "Speed: 2.8ms preprocess, 387.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 517.1ms\n",
      "Speed: 3.4ms preprocess, 517.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 307.0ms\n",
      "Speed: 7.1ms preprocess, 307.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM1, 1 RM5, 274.8ms\n",
      "Speed: 2.9ms preprocess, 274.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 354.2ms\n",
      "Speed: 4.4ms preprocess, 354.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 254.4ms\n",
      "Speed: 3.2ms preprocess, 254.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 288.9ms\n",
      "Speed: 2.6ms preprocess, 288.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 368.1ms\n",
      "Speed: 3.2ms preprocess, 368.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 259.2ms\n",
      "Speed: 3.0ms preprocess, 259.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 271.5ms\n",
      "Speed: 2.5ms preprocess, 271.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 286.2ms\n",
      "Speed: 2.9ms preprocess, 286.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 289.5ms\n",
      "Speed: 2.9ms preprocess, 289.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 1161.8ms\n",
      "Speed: 2.7ms preprocess, 1161.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-18 (webcam_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py\", line 1041, in _bootstrap_inner\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"d:\\Projects-Ng\\Currency_recognition\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py\", line 992, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19800\\1038272056.py\", line 138, in webcam_loop\n",
      "    show_image(img)\n",
      "    ~~~~~~~~~~^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19800\\1038272056.py\", line 103, in show_image\n",
      "    img_tk = ImageTk.PhotoImage(img_pil)\n",
      "  File \"d:\\Projects-Ng\\Currency_recognition\\.venv\\Lib\\site-packages\\PIL\\ImageTk.py\", line 129, in __init__\n",
      "    self.__photo = tkinter.PhotoImage(**kw)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tkinter\\__init__.py\", line 4285, in __init__\n",
      "    Image.__init__(self, 'photo', name, cnf, master, **kw)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tkinter\\__init__.py\", line 4222, in __init__\n",
      "    master = _get_default_root('create image')\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\tkinter\\__init__.py\", line 323, in _get_default_root\n",
      "    raise RuntimeError(f\"Too early to {what}: no default root window\")\n",
      "RuntimeError: Too early to create image: no default root window\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "# ===== Detection summary box =====\n",
    "from tkinter import scrolledtext\n",
    "from collections import Counter\n",
    "import torch\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize TTS engine\n",
    "tts_engine = pyttsx3.init()\n",
    "tts_engine.setProperty('rate', 150)  # Optional: set speaking rate\n",
    "\n",
    "# Global dictionary to store latest detection result\n",
    "latest_detection_summary = {\n",
    "    \"notes\": {},       # e.g., {\"RM10\": 2, \"RM1\": 1}\n",
    "    \"total_amount\": 0  # e.g., 21\n",
    "}\n",
    "\n",
    "# Define class name to monetary value mapping\n",
    "currency_values = {\n",
    "    \"RM1\": 1,\n",
    "    \"RM5\": 5,\n",
    "    \"RM10\": 10,\n",
    "    \"RM20\": 20,\n",
    "    \"RM50\": 50,\n",
    "    \"RM100\": 100\n",
    "}\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"colab/train_results/weights/best.pt\")  # Update this path as needed\n",
    "\n",
    "def update_detection_summary(results):\n",
    "    global latest_detection_summary\n",
    "    try:\n",
    "        cls_tensor = results[0].boxes.cls\n",
    "        cls_list = cls_tensor.tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor\n",
    "        counts = Counter(cls_list)\n",
    "\n",
    "        # Summary string and total computation\n",
    "        summary = \"\"\n",
    "        total_amount = 0\n",
    "        detected_notes = {}\n",
    "\n",
    "        for class_id, count in counts.items():\n",
    "            class_name = model.names[int(class_id)]\n",
    "            note_value = currency_values.get(class_name, 0)\n",
    "            detected_notes[class_name] = count\n",
    "            subtotal = note_value * count\n",
    "            total_amount += subtotal\n",
    "            summary += f\"{class_name}: {count} x RM{note_value} = RM{subtotal}\\n\"\n",
    "\n",
    "        summary += f\"\\nTotal Amount: RM{total_amount}\"\n",
    "\n",
    "        # Update GUI text box\n",
    "        detection_box.config(state=tk.NORMAL)\n",
    "        detection_box.delete(1.0, tk.END)\n",
    "        detection_box.insert(tk.END, summary.strip())\n",
    "        detection_box.config(state=tk.DISABLED)\n",
    "\n",
    "        # Store in global dictionary\n",
    "        latest_detection_summary[\"notes\"] = detected_notes\n",
    "        latest_detection_summary[\"total_amount\"] = total_amount\n",
    "\n",
    "    except Exception as e:\n",
    "        detection_box.config(state=tk.NORMAL)\n",
    "        detection_box.delete(1.0, tk.END)\n",
    "        detection_box.insert(tk.END, f\"Error: {str(e)}\")\n",
    "        detection_box.config(state=tk.DISABLED)\n",
    "\n",
    "def speak_detection_summary():\n",
    "    notes = latest_detection_summary.get(\"notes\", {})\n",
    "    total = latest_detection_summary.get(\"total_amount\", 0)\n",
    "\n",
    "    if not notes:\n",
    "        tts_engine.say(\"No currency notes detected.\")\n",
    "    else:\n",
    "        speech_output = \"Detected currency notes: \"\n",
    "        for note, count in notes.items():\n",
    "            speech_output += f\"{count} piece{'s' if count > 1 else ''} of {note}, \"\n",
    "        speech_output += f\"Total amount is {total} ringgit.\"\n",
    "        tts_engine.say(speech_output)\n",
    "\n",
    "    tts_engine.runAndWait()\n",
    "\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"YOLOv8 GUI Demo\")\n",
    "root.geometry(\"1024x768\")\n",
    "\n",
    "# State variables\n",
    "cap = None\n",
    "running = False\n",
    "\n",
    "# Helper: Show image in GUI\n",
    "def show_image(img_cv2):\n",
    "    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "    img_tk = ImageTk.PhotoImage(img_pil)\n",
    "    panel.imgtk = img_tk\n",
    "    panel.configure(image=img_tk)\n",
    "\n",
    "# Prediction: Run YOLO on static image\n",
    "def predict_image(path):\n",
    "    results = model(path)\n",
    "    img = results[0].plot()\n",
    "    show_image(img)\n",
    "    update_detection_summary(results)\n",
    "\n",
    "# Prediction: Open image\n",
    "def upload_image():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.png *.jpeg\")])\n",
    "    if path:\n",
    "        predict_image(path)\n",
    "\n",
    "# Webcam handling\n",
    "def webcam_loop():\n",
    "    global cap, running\n",
    "    while running:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 👇 Copy and flip the frame horizontally (mirror)\n",
    "        frame_flipped = cv2.flip(frame.copy(), 1)  # 1 = horizontal flip\n",
    "\n",
    "        # Run YOLOv8 on the flipped frame\n",
    "        results = model(frame_flipped)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        img = results[0].plot()\n",
    "\n",
    "        # Display\n",
    "        show_image(img)\n",
    "        update_detection_summary(results)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Start webcam\n",
    "def start_webcam():\n",
    "    global cap, running\n",
    "    stop_all_streams()  # Stop other sources\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    running = True\n",
    "    threading.Thread(target=webcam_loop, daemon=True).start()\n",
    "\n",
    "# Video playback loop\n",
    "def video_loop(path):\n",
    "    global cap, running\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    running = True\n",
    "    while running and cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model(frame)\n",
    "        img = results[0].plot()\n",
    "        show_image(img)\n",
    "        update_detection_summary(results)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "# Upload and play video\n",
    "def upload_video():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4 *.avi *.mov\")])\n",
    "    if path:\n",
    "        stop_all_streams()\n",
    "        threading.Thread(target=video_loop, args=(path,), daemon=True).start()\n",
    "\n",
    "# Stop all video/camera streams\n",
    "def stop_all_streams():\n",
    "    global cap, running\n",
    "    running = False\n",
    "    if cap:\n",
    "        cap.release()\n",
    "        cap = None\n",
    "\n",
    "# Buttons\n",
    "btn_frame = tk.Frame(root)\n",
    "btn_frame.pack(pady=10)\n",
    "\n",
    "# ===== Button Panel on the Left =====\n",
    "button_panel = tk.Frame(root, width=200, bg='lightgray')\n",
    "button_panel.pack(side=\"left\", fill=\"y\")\n",
    "\n",
    "btn_upload_img = tk.Button(button_panel, text=\"Upload Image\", command=upload_image)\n",
    "btn_upload_img.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_upload_vid = tk.Button(button_panel, text=\"Upload Video\", command=upload_video)\n",
    "btn_upload_vid.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_cam_start = tk.Button(button_panel, text=\"Start Webcam\", command=start_webcam)\n",
    "btn_cam_start.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_cam_stop = tk.Button(button_panel, text=\"Stop Webcam\", command=stop_all_streams)\n",
    "btn_cam_stop.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_speak_result = tk.Button(button_panel, text=\"Speak Result\", command=speak_detection_summary)\n",
    "btn_speak_result.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "\n",
    "detection_box = scrolledtext.ScrolledText(button_panel, height=15, width=25, wrap=tk.WORD)\n",
    "detection_box.pack(pady=10, padx=10, fill=\"both\")\n",
    "detection_box.insert(tk.END, \"Detection summary will appear here.\")\n",
    "detection_box.config(state=tk.DISABLED)\n",
    "\n",
    "# ===== Display Panel on the Right =====\n",
    "display_panel = tk.Frame(root, bg='black')\n",
    "display_panel.pack(side=\"right\", expand=True, fill=\"both\")\n",
    "\n",
    "panel = tk.Label(display_panel, bg='black')\n",
    "panel.pack(expand=True)\n",
    "\n",
    "# Run GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
