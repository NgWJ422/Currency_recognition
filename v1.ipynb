{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74c3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd9934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model_path = os.path.join(\"models\", \"best.pt\")\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6199146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: RM1\n",
      "1: RM10\n",
      "2: RM100\n",
      "3: RM20\n",
      "4: RM5\n",
      "5: RM50\n"
     ]
    }
   ],
   "source": [
    "# Print all class labels from the trained model\n",
    "for class_id, class_name in model.names.items():\n",
    "    print(f\"{class_id}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b065485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\Projects-Ng\\Currency_recognition\\assets\\image1.jpg: 320x640 1 RM100, 2440.3ms\n",
      "Speed: 535.2ms preprocess, 2440.3ms inference, 171.8ms postprocess per image at shape (1, 3, 320, 640)\n",
      "\n",
      "0: 480x640 (no detections), 504.1ms\n",
      "Speed: 142.5ms preprocess, 504.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 243.1ms\n",
      "Speed: 5.8ms preprocess, 243.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 251.2ms\n",
      "Speed: 2.5ms preprocess, 251.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 290.8ms\n",
      "Speed: 3.3ms preprocess, 290.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 280.2ms\n",
      "Speed: 2.8ms preprocess, 280.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 278.7ms\n",
      "Speed: 2.8ms preprocess, 278.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 294.4ms\n",
      "Speed: 3.0ms preprocess, 294.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 264.5ms\n",
      "Speed: 3.1ms preprocess, 264.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 301.1ms\n",
      "Speed: 3.3ms preprocess, 301.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 282.3ms\n",
      "Speed: 2.9ms preprocess, 282.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 258.1ms\n",
      "Speed: 2.8ms preprocess, 258.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 289.3ms\n",
      "Speed: 2.9ms preprocess, 289.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 326.9ms\n",
      "Speed: 3.0ms preprocess, 326.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 301.3ms\n",
      "Speed: 2.6ms preprocess, 301.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 274.7ms\n",
      "Speed: 6.0ms preprocess, 274.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 256.8ms\n",
      "Speed: 2.0ms preprocess, 256.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 303.4ms\n",
      "Speed: 3.8ms preprocess, 303.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 241.9ms\n",
      "Speed: 3.5ms preprocess, 241.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 230.7ms\n",
      "Speed: 3.0ms preprocess, 230.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 254.3ms\n",
      "Speed: 2.4ms preprocess, 254.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 239.2ms\n",
      "Speed: 3.0ms preprocess, 239.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 284.5ms\n",
      "Speed: 2.4ms preprocess, 284.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 267.1ms\n",
      "Speed: 2.7ms preprocess, 267.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 278.4ms\n",
      "Speed: 3.4ms preprocess, 278.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 257.2ms\n",
      "Speed: 2.5ms preprocess, 257.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 276.3ms\n",
      "Speed: 2.7ms preprocess, 276.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.9ms\n",
      "Speed: 3.4ms preprocess, 229.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 222.8ms\n",
      "Speed: 2.3ms preprocess, 222.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 226.3ms\n",
      "Speed: 2.1ms preprocess, 226.3ms inference, 25.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 238.1ms\n",
      "Speed: 3.0ms preprocess, 238.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 213.8ms\n",
      "Speed: 2.7ms preprocess, 213.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 229.1ms\n",
      "Speed: 2.1ms preprocess, 229.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 258.8ms\n",
      "Speed: 2.7ms preprocess, 258.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 253.0ms\n",
      "Speed: 3.0ms preprocess, 253.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 223.0ms\n",
      "Speed: 4.6ms preprocess, 223.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 236.1ms\n",
      "Speed: 2.5ms preprocess, 236.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 278.8ms\n",
      "Speed: 2.6ms preprocess, 278.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 234.1ms\n",
      "Speed: 2.7ms preprocess, 234.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 227.0ms\n",
      "Speed: 2.4ms preprocess, 227.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 244.2ms\n",
      "Speed: 2.5ms preprocess, 244.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 240.9ms\n",
      "Speed: 3.3ms preprocess, 240.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 221.2ms\n",
      "Speed: 3.7ms preprocess, 221.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 222.9ms\n",
      "Speed: 2.0ms preprocess, 222.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM1, 1 RM5, 241.1ms\n",
      "Speed: 2.3ms preprocess, 241.1ms inference, 36.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 248.5ms\n",
      "Speed: 2.4ms preprocess, 248.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 221.8ms\n",
      "Speed: 2.4ms preprocess, 221.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 233.3ms\n",
      "Speed: 2.9ms preprocess, 233.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 284.7ms\n",
      "Speed: 2.3ms preprocess, 284.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 232.7ms\n",
      "Speed: 2.6ms preprocess, 232.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 247.6ms\n",
      "Speed: 2.5ms preprocess, 247.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 243.7ms\n",
      "Speed: 2.6ms preprocess, 243.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 RM5, 265.8ms\n",
      "Speed: 2.7ms preprocess, 265.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 172.6ms\n",
      "Speed: 2.0ms preprocess, 172.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 192.2ms\n",
      "Speed: 2.1ms preprocess, 192.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 184.9ms\n",
      "Speed: 2.4ms preprocess, 184.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 187.6ms\n",
      "Speed: 1.9ms preprocess, 187.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 198.2ms\n",
      "Speed: 1.9ms preprocess, 198.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 203.9ms\n",
      "Speed: 2.3ms preprocess, 203.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 227.6ms\n",
      "Speed: 2.3ms preprocess, 227.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 254.6ms\n",
      "Speed: 3.9ms preprocess, 254.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 222.9ms\n",
      "Speed: 2.5ms preprocess, 222.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 225.0ms\n",
      "Speed: 2.3ms preprocess, 225.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 283.8ms\n",
      "Speed: 2.8ms preprocess, 283.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import threading\n",
    "from ultralytics import YOLO\n",
    "# ===== Detection summary box =====\n",
    "from tkinter import scrolledtext\n",
    "from collections import Counter\n",
    "import torch\n",
    "import pyttsx3\n",
    "\n",
    "# Initialize TTS engine\n",
    "tts_engine = pyttsx3.init()\n",
    "tts_engine.setProperty('rate', 150)  # Optional: set speaking rate\n",
    "\n",
    "# Global dictionary to store latest detection result\n",
    "latest_detection_summary = {\n",
    "    \"notes\": {},       # e.g., {\"RM10\": 2, \"RM1\": 1}\n",
    "    \"total_amount\": 0  # e.g., 21\n",
    "}\n",
    "\n",
    "# Define class name to monetary value mapping\n",
    "currency_values = {\n",
    "    \"RM1\": 1,\n",
    "    \"RM5\": 5,\n",
    "    \"RM10\": 10,\n",
    "    \"RM20\": 20,\n",
    "    \"RM50\": 50,\n",
    "    \"RM100\": 100\n",
    "}\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"colab/train_results/weights/best.pt\")  # Update this path as needed\n",
    "\n",
    "def update_detection_summary(results):\n",
    "    global latest_detection_summary\n",
    "    try:\n",
    "        cls_tensor = results[0].boxes.cls\n",
    "        cls_list = cls_tensor.tolist() if isinstance(cls_tensor, torch.Tensor) else cls_tensor\n",
    "        counts = Counter(cls_list)\n",
    "\n",
    "        # Summary string and total computation\n",
    "        summary = \"\"\n",
    "        total_amount = 0\n",
    "        detected_notes = {}\n",
    "\n",
    "        for class_id, count in counts.items():\n",
    "            class_name = model.names[int(class_id)]\n",
    "            note_value = currency_values.get(class_name, 0)\n",
    "            detected_notes[class_name] = count\n",
    "            subtotal = note_value * count\n",
    "            total_amount += subtotal\n",
    "            summary += f\"{class_name}: {count} x RM{note_value} = RM{subtotal}\\n\"\n",
    "\n",
    "        summary += f\"\\nTotal Amount: RM{total_amount}\"\n",
    "\n",
    "        # Update GUI text box\n",
    "        detection_box.config(state=tk.NORMAL)\n",
    "        detection_box.delete(1.0, tk.END)\n",
    "        detection_box.insert(tk.END, summary.strip())\n",
    "        detection_box.config(state=tk.DISABLED)\n",
    "\n",
    "        # Store in global dictionary\n",
    "        latest_detection_summary[\"notes\"] = detected_notes\n",
    "        latest_detection_summary[\"total_amount\"] = total_amount\n",
    "\n",
    "    except Exception as e:\n",
    "        detection_box.config(state=tk.NORMAL)\n",
    "        detection_box.delete(1.0, tk.END)\n",
    "        detection_box.insert(tk.END, f\"Error: {str(e)}\")\n",
    "        detection_box.config(state=tk.DISABLED)\n",
    "\n",
    "def speak_detection_summary():\n",
    "    notes = latest_detection_summary.get(\"notes\", {})\n",
    "    total = latest_detection_summary.get(\"total_amount\", 0)\n",
    "\n",
    "    if not notes:\n",
    "        tts_engine.say(\"No currency notes detected.\")\n",
    "    else:\n",
    "        speech_output = \"Detected currency notes: \"\n",
    "        for note, count in notes.items():\n",
    "            speech_output += f\"{count} piece{'s' if count > 1 else ''} of {note}, \"\n",
    "        speech_output += f\"Total amount is {total} ringgit.\"\n",
    "        tts_engine.say(speech_output)\n",
    "\n",
    "    tts_engine.runAndWait()\n",
    "\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"YOLOv8 GUI Demo\")\n",
    "root.geometry(\"1024x768\")\n",
    "\n",
    "# State variables\n",
    "cap = None\n",
    "running = False\n",
    "\n",
    "# Helper: Show image in GUI\n",
    "def show_image(img_cv2):\n",
    "    img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "    img_pil = Image.fromarray(img_rgb)\n",
    "    img_tk = ImageTk.PhotoImage(img_pil)\n",
    "    panel.imgtk = img_tk\n",
    "    panel.configure(image=img_tk)\n",
    "\n",
    "# Prediction: Run YOLO on static image\n",
    "def predict_image(path):\n",
    "    results = model(path)\n",
    "    img = results[0].plot()\n",
    "    show_image(img)\n",
    "    update_detection_summary(results)\n",
    "\n",
    "# Prediction: Open image\n",
    "def upload_image():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.png *.jpeg\")])\n",
    "    if path:\n",
    "        predict_image(path)\n",
    "\n",
    "# Webcam handling\n",
    "def webcam_loop():\n",
    "    global cap, running\n",
    "    while running:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # ðŸ‘‡ Copy and flip the frame horizontally (mirror)\n",
    "        frame_flipped = cv2.flip(frame.copy(), 1)  # 1 = horizontal flip\n",
    "\n",
    "        # Run YOLOv8 on the flipped frame\n",
    "        results = model(frame_flipped)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        img = results[0].plot()\n",
    "\n",
    "        # Display\n",
    "        show_image(img)\n",
    "        update_detection_summary(results)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Start webcam\n",
    "def start_webcam():\n",
    "    global cap, running\n",
    "    stop_all_streams()  # Stop other sources\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    running = True\n",
    "    threading.Thread(target=webcam_loop, daemon=True).start()\n",
    "\n",
    "# Video playback loop\n",
    "def video_loop(path):\n",
    "    global cap, running\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    running = True\n",
    "    while running and cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model(frame)\n",
    "        img = results[0].plot()\n",
    "        show_image(img)\n",
    "        update_detection_summary(results)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "# Upload and play video\n",
    "def upload_video():\n",
    "    path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4 *.avi *.mov\")])\n",
    "    if path:\n",
    "        stop_all_streams()\n",
    "        threading.Thread(target=video_loop, args=(path,), daemon=True).start()\n",
    "\n",
    "# Stop all video/camera streams\n",
    "def stop_all_streams():\n",
    "    global cap, running\n",
    "    running = False\n",
    "    if cap:\n",
    "        cap.release()\n",
    "        cap = None\n",
    "\n",
    "# Buttons\n",
    "btn_frame = tk.Frame(root)\n",
    "btn_frame.pack(pady=10)\n",
    "\n",
    "# ===== Button Panel on the Left =====\n",
    "button_panel = tk.Frame(root, width=200, bg='lightgray')\n",
    "button_panel.pack(side=\"left\", fill=\"y\")\n",
    "\n",
    "btn_upload_img = tk.Button(button_panel, text=\"Upload Image\", command=upload_image)\n",
    "btn_upload_img.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_upload_vid = tk.Button(button_panel, text=\"Upload Video\", command=upload_video)\n",
    "btn_upload_vid.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_cam_start = tk.Button(button_panel, text=\"Start Webcam\", command=start_webcam)\n",
    "btn_cam_start.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_cam_stop = tk.Button(button_panel, text=\"Stop Webcam\", command=stop_all_streams)\n",
    "btn_cam_stop.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "btn_speak_result = tk.Button(button_panel, text=\"Speak Result\", command=speak_detection_summary)\n",
    "btn_speak_result.pack(pady=10, padx=10, fill=\"x\")\n",
    "\n",
    "\n",
    "detection_box = scrolledtext.ScrolledText(button_panel, height=15, width=25, wrap=tk.WORD)\n",
    "detection_box.pack(pady=10, padx=10, fill=\"both\")\n",
    "detection_box.insert(tk.END, \"Detection summary will appear here.\")\n",
    "detection_box.config(state=tk.DISABLED)\n",
    "\n",
    "# ===== Display Panel on the Right =====\n",
    "display_panel = tk.Frame(root, bg='black')\n",
    "display_panel.pack(side=\"right\", expand=True, fill=\"both\")\n",
    "\n",
    "panel = tk.Label(display_panel, bg='black')\n",
    "panel.pack(expand=True)\n",
    "\n",
    "# Run GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
